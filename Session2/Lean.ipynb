{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30+ Essential Pandas Methods Tutorial\n",
    "\n",
    "A comprehensive guide to the most useful pandas methods using a Yamaha motorcycles dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, update your setup cell\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Configure pandas to not use inf as null\n",
    "pd.options.mode.use_inf_as_na = False\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting configurations\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8')  # Use updated style name\n",
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read Excel file\n",
    "df = pd.read_excel('yamaha_motrocycles.xlsx')\n",
    "\n",
    "# 2. Create a copy for safe manipulation\n",
    "df_clean = df.copy()\n",
    "\n",
    "print('Data loaded successfully!')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Data Inspection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Basic information about the dataset\n",
    "print('Dataset Info:')\n",
    "df.info()\n",
    "\n",
    "# 4. Get column names\n",
    "print('\\nColumns:', df.columns.tolist())\n",
    "\n",
    "# 5. Get data types\n",
    "print('\\nData Types:')\n",
    "print(df.dtypes)\n",
    "\n",
    "# 6. Check for missing values\n",
    "print('\\nMissing Values:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 7. Basic statistics\n",
    "print('\\nBasic Statistics:')\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Selection and Filtering Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Select specific columns\n",
    "if 'Price' in df.columns and 'Model' in df.columns:\n",
    "    selected_cols = df[['Model', 'Price']]\n",
    "    print('Selected columns:')\n",
    "    display(selected_cols.head())\n",
    "\n",
    "# 9. Filter rows by condition\n",
    "if 'Price' in df.columns:\n",
    "    expensive_bikes = df[df['Price'] > df['Price'].mean()]\n",
    "    print('\\nExpensive bikes:')\n",
    "    display(expensive_bikes.head())\n",
    "\n",
    "# 10. Multiple conditions\n",
    "if all(col in df.columns for col in ['Price', 'Year']):\n",
    "    filtered_df = df[(df['Price'] > 10000) & (df['Year'] > 2020)]\n",
    "    print('\\nNew expensive bikes:')\n",
    "    display(filtered_df.head())\n",
    "\n",
    "# 11. Select by index\n",
    "print('\\nFirst 3 rows using iloc:')\n",
    "display(df.iloc[0:3])\n",
    "\n",
    "# 12. Select by label\n",
    "if 'Model' in df.columns:\n",
    "    print('\\nSelect by label using loc:')\n",
    "    display(df.loc[df['Model'].str.contains('R1', na=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Remove duplicates\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "\n",
    "# 14. Handle missing values\n",
    "numeric_cols = df_clean.select_dtypes(include=['number']).columns\n",
    "categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "\n",
    "# 15. Fill numeric missing values with mean\n",
    "df_clean[numeric_cols] = df_clean[numeric_cols].fillna(df_clean[numeric_cols].mean())\n",
    "\n",
    "# 16. Fill categorical missing values with mode\n",
    "df_clean[categorical_cols] = df_clean[categorical_cols].fillna(df_clean[categorical_cols].mode().iloc[0])\n",
    "\n",
    "# 17. Remove outliers (example for Price)\n",
    "if 'Price' in df_clean.columns:\n",
    "    Q1 = df_clean['Price'].quantile(0.25)\n",
    "    Q3 = df_clean['Price'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df_clean = df_clean[(df_clean['Price'] >= Q1 - 1.5*IQR) & \n",
    "                        (df_clean['Price'] <= Q3 + 1.5*IQR)]\n",
    "\n",
    "print('Data cleaning completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Transformation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. Create new calculated column\n",
    "if all(col in df_clean.columns for col in ['Price', 'Year']):\n",
    "    df_clean['Age'] = 2024 - df_clean['Year']\n",
    "    df_clean['Price_per_Year'] = df_clean['Price'] / df_clean['Age']\n",
    "\n",
    "# 19. Apply custom function\n",
    "if 'Price' in df_clean.columns:\n",
    "    df_clean['Price_Category'] = df_clean['Price'].apply(\n",
    "        lambda x: 'High' if x > df_clean['Price'].mean() else 'Low')\n",
    "\n",
    "# 20. String operations\n",
    "if 'Model' in df_clean.columns:\n",
    "    df_clean['Model_Upper'] = df_clean['Model'].str.upper()\n",
    "\n",
    "# 21. Binning\n",
    "if 'Price' in df_clean.columns:\n",
    "    df_clean['Price_Bins'] = pd.qcut(df_clean['Price'], q=4, labels=['Budget', 'Mid', 'Premium', 'Luxury'])\n",
    "\n",
    "# 22. One-hot encoding\n",
    "if len(categorical_cols) > 0:\n",
    "    df_clean = pd.get_dummies(df_clean, columns=[categorical_cols[0]], prefix='cat')\n",
    "\n",
    "print('Transformations completed!')\n",
    "display(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Aggregation and Grouping Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23. Basic groupby operations\n",
    "if 'Price_Category' in df_clean.columns:\n",
    "    group_stats = df_clean.groupby('Price_Category').agg({\n",
    "        'Price': ['count', 'mean', 'median', 'std'],\n",
    "        'Age': 'mean'\n",
    "    })\n",
    "    print('Group statistics:')\n",
    "    display(group_stats)\n",
    "\n",
    "# 24. Pivot table\n",
    "if all(col in df_clean.columns for col in ['Year', 'Price_Category', 'Price']):\n",
    "    pivot_table = pd.pivot_table(\n",
    "        df_clean,\n",
    "        values='Price',\n",
    "        index='Year',\n",
    "        columns='Price_Category',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    print('\\nPivot table:')\n",
    "    display(pivot_table)\n",
    "\n",
    "# 25. Rolling calculations\n",
    "if 'Price' in df_clean.columns:\n",
    "    df_clean['Rolling_Avg_Price'] = df_clean['Price'].rolling(window=3).mean()\n",
    "\n",
    "# 26. Cumulative calculations\n",
    "if 'Price' in df_clean.columns:\n",
    "    df_clean['Cumulative_Sum'] = df_clean['Price'].cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Analysis Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27. Correlation analysis\n",
    "numeric_correlation = df_clean.select_dtypes(include=['number']).corr()\n",
    "print('Correlation matrix:')\n",
    "display(numeric_correlation)\n",
    "\n",
    "# 28. Value counts with percentages\n",
    "if 'Price_Category' in df_clean.columns:\n",
    "    value_counts = df_clean['Price_Category'].value_counts(normalize=True) * 100\n",
    "    print('\\nPrice category distribution (%):')\n",
    "    display(value_counts)\n",
    "\n",
    "# 29. Descriptive statistics by category\n",
    "if 'Price_Category' in df_clean.columns:\n",
    "    category_stats = df_clean.groupby('Price_Category').describe()\n",
    "    print('\\nDetailed statistics by category:')\n",
    "    display(category_stats)\n",
    "\n",
    "# 30. Rank items\n",
    "if 'Price' in df_clean.columns:\n",
    "    df_clean['Price_Rank'] = df_clean['Price'].rank(method='dense', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualization Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations with error handling\n",
    "try:\n",
    "    # Create figure and axes\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 15))\n",
    "\n",
    "    # 31. Histogram\n",
    "    if 'Price' in df_clean.columns:\n",
    "        ax1.hist(df_clean['Price'].dropna(), bins=30)\n",
    "        ax1.set_title('Price Distribution')\n",
    "        ax1.set_xlabel('Price')\n",
    "        ax1.set_ylabel('Count')\n",
    "\n",
    "    # 32. Box plot\n",
    "    if 'Price_Category' in df_clean.columns and 'Price' in df_clean.columns:\n",
    "        sns.boxplot(x='Price_Category', y='Price', data=df_clean.dropna(), ax=ax2)\n",
    "        ax2.set_title('Price by Category')\n",
    "\n",
    "    # 33. Scatter plot\n",
    "    if all(col in df_clean.columns for col in ['Age', 'Price']):\n",
    "        sns.scatterplot(x='Age', y='Price', data=df_clean.dropna(), ax=ax3)\n",
    "        ax3.set_title('Price vs Age')\n",
    "\n",
    "    # 34. Correlation heatmap\n",
    "    corr_data = df_clean.select_dtypes(include=[np.number]).corr()\n",
    "    sns.heatmap(corr_data, \n",
    "                annot=True,\n",
    "                fmt='.2f',\n",
    "                cmap='coolwarm',\n",
    "                center=0,\n",
    "                ax=ax4)\n",
    "    ax4.set_title('Correlation Heatmap')\n",
    "\n",
    "    # Adjust layout and display\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in visualization: {str(e)}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35. Export to Excel with multiple sheets\n",
    "with pd.ExcelWriter('analysis_results.xlsx') as writer:\n",
    "    df_clean.to_excel(writer, sheet_name='Clean_Data', index=False)\n",
    "    numeric_correlation.to_excel(writer, sheet_name='Correlations')\n",
    "    if 'Price_Category' in df_clean.columns:\n",
    "        group_stats.to_excel(writer, sheet_name='Group_Statistics')\n",
    "\n",
    "print('Analysis results saved to analysis_results.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated 35 essential pandas methods across different categories:\n",
    "\n",
    "1. **Basic Operations**: read_excel, info, head, describe\n",
    "2. **Selection**: iloc, loc, boolean indexing\n",
    "3. **Cleaning**: drop_duplicates, fillna, handling outliers\n",
    "4. **Transformation**: apply, string operations, binning\n",
    "5. **Aggregation**: groupby, pivot_table, rolling calculations\n",
    "6. **Analysis**: correlation, value_counts, rank\n",
    "7. **Visualization**: histplot, boxplot, heatmap\n",
    "8. **Export**: to_excel with multiple sheets\n",
    "\n",
    "Each method includes error handling and conditional checks to ensure the code runs with different dataset structures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
